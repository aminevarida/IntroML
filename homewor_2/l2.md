# Отчет по лабораторной работе №2
## Описание отчета
В данной лабораторной работе были изучены и применены на практике алгоритмы k-ближайших соседей (kNN) и линейные модели для задач классификации и регрессии. Работа проводилась на двух наборах данных: Penguins (классификация видов пингвинов) и Diamonds (предсказание цены бриллиантов).
## Используемые библиотеки
- **Pandas** - для обработки и анализа данных
- **NumPy** - для математических операций
- **Matplotlib** - для визуализации данных
## Задание 1
### kNN и визуализация решающих поверхностей
#### Предобработка данных
- Обработка пропущенных значений: В наборе данных  Penguins были обнаружены пропущенные значения, которые были удалены для обеспечения качества анализа.

- Кодирование категориальных признаков.

- Кодирование целевой переменной: Виды пингвинов были закодированы в ординальном порядке: Chinstrap = 0, Gentoo = 1, Adelie = 2.
#### Разделение данных
Данные были разделены на тренировочную  и тестовую  выборки с использованием стратификации для сохранения распределения классов в обеих выборках.
### Обучение kNN-классификаторов
Было обучено 6 kNN-классификаторов с различными значениями k (1, 3, 5, 10, 15, 25) на двух признаках: длина ласт и масса тела.
#### Анализ результатов
- k=1: Демонстрирует признаки переобучения - высокая точность на тренировочных данных (97%), но низкая на тестовых (74%).

- k=3-10: Показывают баланс между точностью на тренировочных и тестовых данных.

- k=25: Демонстрирует наилучшую обобщающую способность с точностью 84% на тестовой выборке.

- Оптимальное k: k=25, так как обеспечивает наилучшую точность на тестовой выборке и показывает хорошую обобщающую способность.
## Задание 2
### Был реализован алгоритм kNN с использованием векторных операций NumPy для эффективного вычисления расстояний.
#### Тестирование
Реализация прошла все тесты, включая:
- Базовый случай с k=1
- Классификацию с k=3
- Обработку нескольких тестовых образцов
#### Применение к данным о пингвинах
Лучший результат на тестовой выборке: k=1 с точностью 1.0000
## Задание 3
### Линейная регрессия
#### Предобработка данных Diamonds
- Удалены пропущенные значения
- Удален бессмысленный столбец "Unnamed: 0"
- Категориальные признаки закодированы
#### Анализ корреляций
Наибольшую корреляцию с целевой переменной (price) имеют:
- carat (0.92)
- x (0.88)
- y (0.87)
### Подбор оптимального α для Lasso
ЛУЧШИЕ АЛЬФА ПО РЕЗУЛЬТАТАМ CV:
- Alpha с минимальной MSE: 0.3556 (MSE = 1294514.64)
- Alpha, выбранное LassoCV: 0.3556 (MSE = 1294514.64)
## Вывод
- Чрезмерно малые значения k приводят к переобучению
- Слишком большие значения k могут привести к недообучению
- Lasso-регрессия эффективна для отбора признаков
- Регуляризация помогает улучшить обобщающую способность
Лабораторная работа позволила получить практический опыт работы с алгоритмами kNN и линейными моделями, а также понять важность правильной предобработки данных и настройки гиперпараметров.
